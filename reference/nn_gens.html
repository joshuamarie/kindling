<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Functions to generate nn_module (language) expression — nn_gens • kindling</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><!-- katex math --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><script src="../katex-auto.js"></script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Playfair_Display-0.4.10/font.css" rel="stylesheet"><link href="../deps/Fira_Mono-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Functions to generate nn_module (language) expression — nn_gens"><meta name="description" content="Functions to generate nn_module (language) expression"><meta property="og:description" content="Functions to generate nn_module (language) expression"><meta property="og:image" content="https://kindling.joshuamarie.com/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">kindling</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/kindling.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/kindling.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/similar-packages.html">Similar packages and comparison</a></li>
    <li><a class="dropdown-item" href="../articles/tuning-capabilities.html">Tuning Capabilities</a></li>
  </ul></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-learn-more" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Learn more</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-learn-more"><li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/models/parsnip-ranger-glmnet/">Regression modeling</a></li>
    <li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/models/parsnip-nnet/">Classification modeling</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/joshuamarie/kindling" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
<li class="nav-item"><a class="external-link nav-link" href="https://joshuamarie.com"><span class="fa fa-blog"></span> Blog</a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Functions to generate <code>nn_module</code> (language) expression</h1>
      <small class="dont-index">Source: <a href="https://github.com/joshuamarie/kindling/blob/main/R/torch_nn_generator.R" class="external-link"><code>R/torch_nn_generator.R</code></a></small>
      <div class="d-none name"><code>nn_gens.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Functions to generate <code>nn_module</code> (language) expression</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">ffnn_generator</span><span class="op">(</span></span>
<span>  nn_name <span class="op">=</span> <span class="st">"DeepFFN"</span>,</span>
<span>  <span class="va">hd_neurons</span>,</span>
<span>  <span class="va">no_x</span>,</span>
<span>  <span class="va">no_y</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">rnn_generator</span><span class="op">(</span></span>
<span>  nn_name <span class="op">=</span> <span class="st">"DeepRNN"</span>,</span>
<span>  <span class="va">hd_neurons</span>,</span>
<span>  <span class="va">no_x</span>,</span>
<span>  <span class="va">no_y</span>,</span>
<span>  rnn_type <span class="op">=</span> <span class="st">"lstm"</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bidirectional <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  dropout <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-nn-name">nn_name<a class="anchor" aria-label="anchor" href="#arg-nn-name"></a></dt>
<dd><p>Character. Name of the generated RNN module class. Default is <code>"DeepRNN"</code>.</p></dd>


<dt id="arg-hd-neurons">hd_neurons<a class="anchor" aria-label="anchor" href="#arg-hd-neurons"></a></dt>
<dd><p>Integer vector. Number of neurons in each hidden RNN layer.</p></dd>


<dt id="arg-no-x">no_x<a class="anchor" aria-label="anchor" href="#arg-no-x"></a></dt>
<dd><p>Integer. Number of input features.</p></dd>


<dt id="arg-no-y">no_y<a class="anchor" aria-label="anchor" href="#arg-no-y"></a></dt>
<dd><p>Integer. Number of output features.</p></dd>


<dt id="arg-activations">activations<a class="anchor" aria-label="anchor" href="#arg-activations"></a></dt>
<dd><p>Activation function specifications for each hidden layer.
Can be:</p><ul><li><p><code>NULL</code>: No activation functions.</p></li>
<li><p>Character vector: e.g., <code>c("relu", "sigmoid")</code>.</p></li>
<li><p>List: e.g., <code>act_funs(relu, elu, softshrink = args(lambd = 0.5))</code>.</p></li>
<li><p><code>activation_spec</code> object from <code><a href="act_funs.html">act_funs()</a></code>.</p></li>
</ul><p>If the length of <code>activations</code> is <code>1L</code>, this will be the activation throughout the architecture.</p></dd>


<dt id="arg-output-activation">output_activation<a class="anchor" aria-label="anchor" href="#arg-output-activation"></a></dt>
<dd><p>Optional. Activation function for the output layer.
Same format as <code>activations</code> but should be a single activation.</p></dd>


<dt id="arg-bias">bias<a class="anchor" aria-label="anchor" href="#arg-bias"></a></dt>
<dd><p>Logical. Whether to use bias weights. Default is <code>TRUE</code></p></dd>


<dt id="arg-rnn-type">rnn_type<a class="anchor" aria-label="anchor" href="#arg-rnn-type"></a></dt>
<dd><p>Character. Type of RNN to use. Must be one of <code>"rnn"</code>, <code>"lstm"</code>, or <code>"gru"</code>. Default is <code>"lstm"</code>.</p></dd>


<dt id="arg-bidirectional">bidirectional<a class="anchor" aria-label="anchor" href="#arg-bidirectional"></a></dt>
<dd><p>Logical. Whether to use bidirectional RNN layers. Default is <code>TRUE</code>.</p></dd>


<dt id="arg-dropout">dropout<a class="anchor" aria-label="anchor" href="#arg-dropout"></a></dt>
<dd><p>Numeric. Dropout rate between RNN layers. Default is <code>0</code>.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Additional arguments (currently unused).</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A <code>torch</code> module expression representing the FFNN.</p>
<p>A <code>torch</code> module expression representing the RNN.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The generated FFNN module will have the specified number of hidden layers,
with each layer containing the specified number of neurons. Activation functions
can be applied after each hidden layer as specified.
This can be used for both classification and regression tasks.</p>
<p>The generated module properly namespaces all torch functions to avoid
polluting the global namespace.</p>
<p>The generated RNN module will have the specified number of recurrent layers,
with each layer containing the specified number of hidden units. Activation functions
can be applied after each RNN layer as specified. The final output is taken from the
last time step and passed through a linear layer.</p>
<p>The generated module properly namespaces all torch functions to avoid
polluting the global namespace.</p>
    </div>
    <div class="section level2">
    <h2 id="feed-forward-neural-network-module-generator">Feed-Forward Neural Network Module Generator<a class="anchor" aria-label="anchor" href="#feed-forward-neural-network-module-generator"></a></h2>


<p>The <code>ffnn_generator()</code> function generates a feed-forward neural network (FFNN) module expression
from the <code>torch</code> package in R. It allows customization of the FFNN architecture,
including the number of hidden layers, neurons, and activation functions.</p>
    </div>
    <div class="section level2">
    <h2 id="recurrent-neural-network-module-generator">Recurrent Neural Network Module Generator<a class="anchor" aria-label="anchor" href="#recurrent-neural-network-module-generator"></a></h2>


<p>The <code>rnn_generator()</code> function generates a recurrent neural network (RNN) module expression
from the <code>torch</code> package in R. It allows customization of the RNN architecture,
including the number of hidden layers, neurons, RNN type, activation functions,
and other parameters.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># FFNN</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_is_installed.html" class="external-link">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="co"># Generate an MLP module with 3 hidden layers</span></span></span>
<span class="r-in"><span>    <span class="va">ffnn_mod</span> <span class="op">=</span> <span class="fu">ffnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"MyFFNN"</span>,</span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span>, <span class="fl">16</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">10</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">1</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">'relu'</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Evaluate and instantiate</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/eval.html" class="external-link">eval</a></span><span class="op">(</span><span class="va">ffnn_mod</span><span class="op">)</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># More complex: With different activations</span></span></span>
<span class="r-in"><span>    <span class="va">ffnn_mod2</span> <span class="op">=</span> <span class="fu">ffnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"MyFFNN2"</span>,</span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">20</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="fu"><a href="act_funs.html">act_funs</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>            <span class="va">relu</span>,</span></span>
<span class="r-in"><span>            <span class="va">selu</span>,</span></span>
<span class="r-in"><span>            <span class="va">sigmoid</span></span></span>
<span class="r-in"><span>        <span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Even more complex: Different activations and customized argument</span></span></span>
<span class="r-in"><span>    <span class="co"># for the specific activation function</span></span></span>
<span class="r-in"><span>    <span class="va">ffnn_mod2</span> <span class="op">=</span> <span class="fu">ffnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"MyFFNN2"</span>,</span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">20</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="fu"><a href="act_funs.html">act_funs</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>            <span class="va">relu</span>,</span></span>
<span class="r-in"><span>            <span class="va">selu</span>,</span></span>
<span class="r-in"><span>            softshrink <span class="op">=</span> <span class="fu"><a href="args.html">args</a></span><span class="op">(</span>lambd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Customize output activation (softmax is useful for classification tasks)</span></span></span>
<span class="r-in"><span>    <span class="va">ffnn_mod3</span> <span class="op">=</span> <span class="fu">ffnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">10</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">3</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">'relu'</span>,</span></span>
<span class="r-in"><span>        output_activation <span class="op">=</span> <span class="fu"><a href="act_funs.html">act_funs</a></span><span class="op">(</span>softmax <span class="op">=</span> <span class="fu"><a href="args.html">args</a></span><span class="op">(</span>dim <span class="op">=</span> <span class="fl">2L</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Torch not fully installed — skipping example"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co">## RNN</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_is_installed.html" class="external-link">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="co"># Basic LSTM with 2 layers</span></span></span>
<span class="r-in"><span>    <span class="va">rnn_mod</span> <span class="op">=</span> <span class="fu">rnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"MyLSTM"</span>,</span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">10</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">1</span>,</span></span>
<span class="r-in"><span>        rnn_type <span class="op">=</span> <span class="st">"lstm"</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">'relu'</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Evaluate and instantiate</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/eval.html" class="external-link">eval</a></span><span class="op">(</span><span class="va">rnn_mod</span><span class="op">)</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># GRU with different activations</span></span></span>
<span class="r-in"><span>    <span class="va">rnn_mod2</span> <span class="op">=</span> <span class="fu">rnn_generator</span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"MyGRU"</span>,</span></span>
<span class="r-in"><span>        hd_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        no_x <span class="op">=</span> <span class="fl">20</span>,</span></span>
<span class="r-in"><span>        no_y <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>        rnn_type <span class="op">=</span> <span class="st">"gru"</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="fu"><a href="act_funs.html">act_funs</a></span><span class="op">(</span><span class="va">relu</span>, <span class="va">elu</span>, <span class="va">relu</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        bidirectional <span class="op">=</span> <span class="cn">FALSE</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Torch not fully installed — skipping example"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co">## Parameterized activation and dropout</span></span></span>
<span class="r-in"><span><span class="co"># (Will throw an error due to `nnf_tanh()` not being available in `{torch}`)</span></span></span>
<span class="r-in"><span><span class="co"># rnn_mod3 = rnn_generator(</span></span></span>
<span class="r-in"><span><span class="co">#     hd_neurons = c(100, 50, 25),</span></span></span>
<span class="r-in"><span><span class="co">#     no_x = 15,</span></span></span>
<span class="r-in"><span><span class="co">#     no_y = 3,</span></span></span>
<span class="r-in"><span><span class="co">#     rnn_type = "lstm",</span></span></span>
<span class="r-in"><span><span class="co">#     activations = act_funs(</span></span></span>
<span class="r-in"><span><span class="co">#         relu,</span></span></span>
<span class="r-in"><span><span class="co">#         leaky_relu = args(negative_slope = 0.01),</span></span></span>
<span class="r-in"><span><span class="co">#         tanh</span></span></span>
<span class="r-in"><span><span class="co">#     ),</span></span></span>
<span class="r-in"><span><span class="co">#     bidirectional = TRUE,</span></span></span>
<span class="r-in"><span><span class="co">#     dropout = 0.3</span></span></span>
<span class="r-in"><span><span class="co"># )</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Joshua Marie.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a>. Visit my <a href="https://joshuamarie.com" class="external-link">blog</a> for more content.</p>
</div>

    </footer></div>





  </body></html>

