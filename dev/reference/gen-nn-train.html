<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Generalized Neural Network Trainer — gen-nn-train • kindling</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><!-- katex math --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><script src="../katex-auto.js"></script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Playfair_Display-0.4.10/font.css" rel="stylesheet"><link href="../deps/Fira_Mono-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Generalized Neural Network Trainer — gen-nn-train"><meta name="description" content="
train_nn() is a generic function for training neural networks with a
user-defined architecture via nn_arch(). Dispatch is based on the class
of x.
Recommended workflow:
Define architecture with nn_arch() (optional).
Train with train_nn().
Predict with predict.nn_fit().


All methods delegate to a shared implementation core after preprocessing.
When architecture = NULL, the model falls back to a plain feed-forward neural network
(nn_linear) architecture."><meta property="og:description" content="
train_nn() is a generic function for training neural networks with a
user-defined architecture via nn_arch(). Dispatch is based on the class
of x.
Recommended workflow:
Define architecture with nn_arch() (optional).
Train with train_nn().
Predict with predict.nn_fit().


All methods delegate to a shared implementation core after preprocessing.
When architecture = NULL, the model falls back to a plain feed-forward neural network
(nn_linear) architecture."><meta property="og:image" content="https://kindling.joshuamarie.com/logo.png"><meta name="robots" content="noindex"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">kindling</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.2.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/kindling.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/kindling.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/similar-packages.html">Similar packages and comparison</a></li>
    <li><a class="dropdown-item" href="../articles/tuning-capabilities.html">Tuning Capabilities</a></li>
    <li><a class="dropdown-item" href="../articles/special-cases.html">Linear and Logistic Regression (Special Cases)</a></li>
    <li><a class="dropdown-item" href="../articles/custom-act-fn.html">Custom Activation Function</a></li>
  </ul></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-learn-more" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Learn more</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-learn-more"><li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/models/parsnip-ranger-glmnet/">Regression modeling</a></li>
    <li><a class="external-link dropdown-item" href="https://www.tidymodels.org/learn/models/parsnip-nnet/">Classification modeling</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/joshuamarie/kindling" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
<li class="nav-item"><a class="external-link nav-link" href="https://joshuamarie.com"><span class="fa fa-blog"></span> Blog</a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Generalized Neural Network Trainer</h1>
      <small class="dont-index">Source: <a href="https://github.com/joshuamarie/kindling/blob/main/R/generalized-nn-fit.R" class="external-link"><code>R/generalized-nn-fit.R</code></a>, <a href="https://github.com/joshuamarie/kindling/blob/main/R/generalized-nn-fitds.R" class="external-link"><code>R/generalized-nn-fitds.R</code></a></small>
      <div class="d-none name"><code>gen-nn-train.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental" class="external-link"><img src="figures/lifecycle-experimental.svg" alt="[Experimental]"></a></p>
<p><code>train_nn()</code> is a generic function for training neural networks with a
user-defined architecture via <code><a href="nn_arch.html">nn_arch()</a></code>. Dispatch is based on the class
of <code>x</code>.</p>
<p>Recommended workflow:</p><ol><li><p>Define architecture with <code><a href="nn_arch.html">nn_arch()</a></code> (optional).</p></li>
<li><p>Train with <code>train_nn()</code>.</p></li>
<li><p>Predict with <code><a href="gen-nn-predict.html">predict.nn_fit()</a></code>.</p></li>
</ol><p>All methods delegate to a shared implementation core after preprocessing.
When <code>architecture = NULL</code>, the model falls back to a plain feed-forward neural network
(<code>nn_linear</code>) architecture.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">train_nn</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'matrix'</span></span>
<span><span class="fu">train_nn</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  <span class="va">y</span>,</span>
<span>  hidden_neurons <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  arch <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  architecture <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  early_stopping <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  penalty <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  mixture <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  learn_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  optimizer_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  device <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  cache_weights <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'data.frame'</span></span>
<span><span class="fu">train_nn</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  <span class="va">y</span>,</span>
<span>  hidden_neurons <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  arch <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  architecture <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  early_stopping <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  penalty <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  mixture <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  learn_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  optimizer_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  device <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  cache_weights <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'formula'</span></span>
<span><span class="fu">train_nn</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  <span class="va">data</span>,</span>
<span>  hidden_neurons <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  arch <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  architecture <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  early_stopping <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  penalty <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  mixture <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  learn_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  optimizer_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  device <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  cache_weights <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Default S3 method</span></span>
<span><span class="fu">train_nn</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'dataset'</span></span>
<span><span class="fu">train_nn</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  y <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  hidden_neurons <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  activations <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  output_activation <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bias <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  arch <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  architecture <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  flatten_input <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  penalty <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  mixture <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  learn_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  optimizer_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  device <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  cache_weights <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  n_classes <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-x">x<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p>Dispatch is based on its current class:</p><ul><li><p><code>matrix</code>: used directly, no preprocessing applied.</p></li>
<li><p><code>data.frame</code>: preprocessed via <code><a href="https://hardhat.tidymodels.org/reference/mold.html" class="external-link">hardhat::mold()</a></code>. <code>y</code> may be a vector /
factor / matrix of outcomes, or a formula describing the outcome–predictor
relationship within <code>x</code>.</p></li>
<li><p><code>formula</code>: combined with <code>data</code> and preprocessed via <code><a href="https://hardhat.tidymodels.org/reference/mold.html" class="external-link">hardhat::mold()</a></code>.</p></li>
<li><p><code>dataset</code>: a <code>torch</code> dataset object; batched via <code><a href="https://torch.mlverse.org/docs/reference/dataloader.html" class="external-link">torch::dataloader()</a></code>.
This is the recommended interface for sequence/time-series and image data.</p></li>
</ul></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Additional arguments passed to specific methods.</p></dd>


<dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>Outcome data. Interpretation depends on the method:</p><ul><li><p>For the <code>matrix</code> and <code>data.frame</code> methods: a numeric vector, factor, or
matrix of outcomes.</p></li>
<li><p>For the <code>data.frame</code> method only: alternatively a formula of the form
<code>outcome ~ predictors</code>, evaluated against <code>x</code>.</p></li>
<li><p>Ignored when <code>x</code> is a formula (outcome is taken from the formula) or a
<code>dataset</code> (labels come from the dataset itself).</p></li>
</ul></dd>


<dt id="arg-hidden-neurons">hidden_neurons<a class="anchor" aria-label="anchor" href="#arg-hidden-neurons"></a></dt>
<dd><p>Integer vector specifying the number of neurons in each
hidden layer, e.g. <code>c(128, 64)</code> for two hidden layers. When <code>NULL</code> or missing,
no hidden layers are used and the model reduces to a single linear mapping
from inputs to outputs.</p></dd>


<dt id="arg-activations">activations<a class="anchor" aria-label="anchor" href="#arg-activations"></a></dt>
<dd><p>Activation function specification(s) for the hidden layers.
See <code><a href="act_funs.html">act_funs()</a></code> for supported values. Recycled if a single value is given.</p></dd>


<dt id="arg-output-activation">output_activation<a class="anchor" aria-label="anchor" href="#arg-output-activation"></a></dt>
<dd><p>Optional activation function for the output layer.
Defaults to <code>NULL</code> (no activation / linear output).</p></dd>


<dt id="arg-bias">bias<a class="anchor" aria-label="anchor" href="#arg-bias"></a></dt>
<dd><p>Logical. Whether to include bias terms in each layer. Default <code>TRUE</code>.</p></dd>


<dt id="arg-arch">arch<a class="anchor" aria-label="anchor" href="#arg-arch"></a></dt>
<dd><p>Backward-compatible alias for <code>architecture</code>. If both are supplied,
they must be identical.</p></dd>


<dt id="arg-architecture">architecture<a class="anchor" aria-label="anchor" href="#arg-architecture"></a></dt>
<dd><p>An <code><a href="nn_arch.html">nn_arch()</a></code> object specifying a custom architecture. Default
<code>NULL</code>, which falls back to a standard feed-forward network.</p></dd>


<dt id="arg-early-stopping">early_stopping<a class="anchor" aria-label="anchor" href="#arg-early-stopping"></a></dt>
<dd><p>An <code><a href="early_stop.html">early_stop()</a></code> object specifying early stopping
behaviour, or <code>NULL</code> (default) to disable early stopping. When supplied,
training halts if the monitored metric does not improve by at least
<code>min_delta</code> for <code>patience</code> consecutive epochs.
Example: <code>early_stopping = early_stop(patience = 10)</code>.</p></dd>


<dt id="arg-epochs">epochs<a class="anchor" aria-label="anchor" href="#arg-epochs"></a></dt>
<dd><p>Positive integer. Number of full passes over the training data.
Default <code>100</code>.</p></dd>


<dt id="arg-batch-size">batch_size<a class="anchor" aria-label="anchor" href="#arg-batch-size"></a></dt>
<dd><p>Positive integer. Number of samples per mini-batch. Default <code>32</code>.</p></dd>


<dt id="arg-penalty">penalty<a class="anchor" aria-label="anchor" href="#arg-penalty"></a></dt>
<dd><p>Non-negative numeric. L1/L2 regularization strength (lambda).
Default <code>0</code> (no regularization).</p></dd>


<dt id="arg-mixture">mixture<a class="anchor" aria-label="anchor" href="#arg-mixture"></a></dt>
<dd><p>Numeric in [0, 1]. Elastic net mixing parameter: <code>0</code> = pure
ridge (L2), <code>1</code> = pure lasso (L1). Default <code>0</code>.</p></dd>


<dt id="arg-learn-rate">learn_rate<a class="anchor" aria-label="anchor" href="#arg-learn-rate"></a></dt>
<dd><p>Positive numeric. Step size for the optimizer. Default <code>0.001</code>.</p></dd>


<dt id="arg-optimizer">optimizer<a class="anchor" aria-label="anchor" href="#arg-optimizer"></a></dt>
<dd><p>Character. Optimizer algorithm. One of <code>"adam"</code> (default),
<code>"sgd"</code>, or <code>"rmsprop"</code>.</p></dd>


<dt id="arg-optimizer-args">optimizer_args<a class="anchor" aria-label="anchor" href="#arg-optimizer-args"></a></dt>
<dd><p>Named list of additional arguments forwarded to the
optimizer constructor (e.g. <code>list(momentum = 0.9)</code> for SGD). Default <code><a href="https://rdrr.io/r/base/list.html" class="external-link">list()</a></code>.</p></dd>


<dt id="arg-loss">loss<a class="anchor" aria-label="anchor" href="#arg-loss"></a></dt>
<dd><p>Character or function. Loss function used during training. Built-in
options: <code>"mse"</code> (default), <code>"mae"</code>, <code>"cross_entropy"</code>, or <code>"bce"</code>. For
classification tasks with a scalar label, <code>"cross_entropy"</code> is set
automatically. Alternatively, supply a custom function or formula with
signature <code>function(input, target)</code> returning a scalar <code>torch_tensor</code>.</p></dd>


<dt id="arg-validation-split">validation_split<a class="anchor" aria-label="anchor" href="#arg-validation-split"></a></dt>
<dd><p>Numeric in [0, 1). Proportion of training data held
out for validation. Default <code>0</code> (no validation set).</p></dd>


<dt id="arg-device">device<a class="anchor" aria-label="anchor" href="#arg-device"></a></dt>
<dd><p>Character. Compute device: <code>"cpu"</code>, <code>"cuda"</code>, or <code>"mps"</code>.
Default <code>NULL</code>, which auto-detects the best available device.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>Logical. If <code>TRUE</code>, prints loss (and validation loss) at regular
intervals during training. Default <code>FALSE</code>.</p></dd>


<dt id="arg-cache-weights">cache_weights<a class="anchor" aria-label="anchor" href="#arg-cache-weights"></a></dt>
<dd><p>Logical. If <code>TRUE</code>, stores a copy of the trained weight
matrices in the returned object under <code>$cached_weights</code>. Default <code>FALSE</code>.</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A data frame. Required when <code>x</code> is a formula.</p></dd>


<dt id="arg-flatten-input">flatten_input<a class="anchor" aria-label="anchor" href="#arg-flatten-input"></a></dt>
<dd><p>Logical or <code>NULL</code> (dataset method only). Controls whether
each batch/sample is flattened to 2D before entering the model. <code>NULL</code>
(default) auto-selects: <code>TRUE</code> when <code>architecture = NULL</code>, otherwise <code>FALSE</code>.</p></dd>


<dt id="arg-n-classes">n_classes<a class="anchor" aria-label="anchor" href="#arg-n-classes"></a></dt>
<dd><p>Positive integer. Number of output classes. Required when
<code>x</code> is a <code>dataset</code> with scalar (classification) labels; ignored otherwise.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>An object of class <code>"nn_fit"</code>, or one of its subclasses:</p><ul><li><p><code>c("nn_fit_tab", "nn_fit")</code> — returned by the <code>data.frame</code> and <code>formula</code> methods</p></li>
<li><p><code>c("nn_fit_ds", "nn_fit")</code> — returned by the <code>dataset</code> method</p></li>
</ul><p>All subclasses share a common structure. See <strong>Details</strong> for the list of
components.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The returned <code>"nn_fit"</code> object is a named list with the following components:</p><ul><li><p><code>model</code> — the trained <code><a href="https://torch.mlverse.org/docs/reference/nn_module.html" class="external-link">torch::nn_module</a></code> object</p></li>
<li><p><code>fitted</code> — fitted values on the training data (or <code>NULL</code> for dataset fits)</p></li>
<li><p><code>loss_history</code> — numeric vector of per-epoch training loss, trimmed to
actual epochs run (relevant when early stopping is active)</p></li>
<li><p><code>val_loss_history</code> — per-epoch validation loss, or <code>NULL</code> if
<code>validation_split = 0</code></p></li>
<li><p><code>n_epochs</code> — number of epochs actually trained</p></li>
<li><p><code>stopped_epoch</code> — epoch at which early stopping triggered, or <code>NA</code> if
training ran to completion</p></li>
<li><p><code>hidden_neurons</code>, <code>activations</code>, <code>output_activation</code> — architecture spec</p></li>
<li><p><code>penalty</code>, <code>mixture</code> — regularization settings</p></li>
<li><p><code>feature_names</code>, <code>response_name</code> — variable names (tabular methods only)</p></li>
<li><p><code>no_x</code>, <code>no_y</code> — number of input features and output nodes</p></li>
<li><p><code>is_classification</code> — logical flag</p></li>
<li><p><code>y_levels</code>, <code>n_classes</code> — class labels and count (classification only)</p></li>
<li><p><code>device</code> — device the model is on</p></li>
<li><p><code>cached_weights</code> — list of weight matrices, or <code>NULL</code></p></li>
<li><p><code>arch</code> — the <code>nn_arch</code> object used, or <code>NULL</code></p></li>
</ul></div>
    <div class="section level2">
    <h2 id="supported-tasks-and-input-formats">Supported tasks and input formats<a class="anchor" aria-label="anchor" href="#supported-tasks-and-input-formats"></a></h2>


<p><code>train_nn()</code> is task-agnostic by design (no explicit <code>task</code> argument).
Task behavior is determined by your input interface and architecture:</p><ul><li><p><strong>Tabular data</strong>: use <code>matrix</code>, <code>data.frame</code>, or <code>formula</code> methods.</p></li>
<li><p><strong>Time series</strong>: use the <code>dataset</code> method with per-item tensors shaped as
<code>[time, features]</code> (or your preferred convention) and a recurrent
architecture via <code><a href="nn_arch.html">nn_arch()</a></code>.</p></li>
<li><p><strong>Image classification</strong>: use the <code>dataset</code> method with per-item tensors
shaped for your first layer (commonly <code>[channels, height, width]</code> for
<code><a href="https://torch.mlverse.org/docs/reference/nn_conv2d.html" class="external-link">torch::nn_conv2d</a></code>). If your source arrays are channel-last, reorder in the
dataset or via <code>input_transform</code>.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="matrix-method">Matrix method<a class="anchor" aria-label="anchor" href="#matrix-method"></a></h2>


<p>When <code>x</code> is supplied as a raw numeric matrix, no preprocessing is applied.
Data is passed directly to the shared <code>train_nn_impl</code> core.</p>
    </div>
    <div class="section level2">
    <h2 id="data-frame-method">Data frame method<a class="anchor" aria-label="anchor" href="#data-frame-method"></a></h2>


<p>When <code>x</code> is a data frame, <code>y</code> can be either a vector / factor / matrix of
outcomes, or a formula of the form <code>outcome ~ predictors</code> evaluated against
<code>x</code>. Preprocessing is handled by <code><a href="https://hardhat.tidymodels.org/reference/mold.html" class="external-link">hardhat::mold()</a></code>.</p>
    </div>
    <div class="section level2">
    <h2 id="formula-method">Formula method<a class="anchor" aria-label="anchor" href="#formula-method"></a></h2>


<p>When <code>x</code> is a formula, <code>data</code> must be supplied as the data frame against
which the formula is evaluated. Preprocessing is handled by <code><a href="https://hardhat.tidymodels.org/reference/mold.html" class="external-link">hardhat::mold()</a></code>.</p>
    </div>
    <div class="section level2">
    <h2 id="dataset-method-train-nn-dataset-">Dataset method (<code>train_nn.dataset()</code>)<a class="anchor" aria-label="anchor" href="#dataset-method-train-nn-dataset-"></a></h2>


<p>Trains a neural network directly on a <code>torch</code> dataset object. Batching and
lazy loading are handled by <code><a href="https://torch.mlverse.org/docs/reference/dataloader.html" class="external-link">torch::dataloader()</a></code>, making this method
well-suited for large datasets that do not fit entirely in memory.</p>
<p>Architecture configuration follows the same contract as other <code>train_nn()</code>
methods via <code>architecture = nn_arch(...)</code> (or legacy <code>arch = ...</code>).
For non-tabular inputs (time series, images), set <code>flatten_input = FALSE</code> to
preserve tensor dimensions expected by recurrent or convolutional layers.</p>
<p>Labels are taken from the second element of each dataset item (i.e.
<code>dataset[[i]][[2]]</code>), so <code>y</code> is ignored. When the label is a scalar tensor,
a classification task is assumed and <code>n_classes</code> must be supplied. The loss
is automatically switched to <code>"cross_entropy"</code> in that case.</p>
<p>Fitted values are <strong>not</strong> cached in the returned object. Use
<code><a href="gen-nn-predict.html">predict.nn_fit_ds()</a></code> with <code>newdata</code> to obtain predictions after training.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="gen-nn-predict.html">predict.nn_fit()</a></code>, <code><a href="nn_arch.html">nn_arch()</a></code>, <code><a href="act_funs.html">act_funs()</a></code>, <code><a href="early_stop.html">early_stop()</a></code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_is_installed.html" class="external-link">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="co"># Matrix method — no preprocessing</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        y <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Sepal.Length</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Data frame method — y as a vector</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        y <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Sepal.Length</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Data frame method — y as a formula evaluated against x</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">iris</span>,</span></span>
<span class="r-in"><span>        y <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">Species</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Formula method — outcome derived from formula</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span>,</span></span>
<span class="r-in"><span>        data <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># No hidden layers — linear model</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span>,</span></span>
<span class="r-in"><span>        data <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Architecture object (nn_arch -&gt; train_nn)</span></span></span>
<span class="r-in"><span>    <span class="va">mlp_arch</span> <span class="op">=</span> <span class="fu"><a href="nn_arch.html">nn_arch</a></span><span class="op">(</span>nn_name <span class="op">=</span> <span class="st">"mlp_model"</span><span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span>,</span></span>
<span class="r-in"><span>        data <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        architecture <span class="op">=</span> <span class="va">mlp_arch</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># Custom layer architecture</span></span></span>
<span class="r-in"><span>    <span class="va">custom_linear</span> <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_module.html" class="external-link">nn_module</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>        <span class="st">"CustomLinear"</span>,</span></span>
<span class="r-in"><span>        initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">in_features</span>, <span class="va">out_features</span>, <span class="va">bias</span> <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>            <span class="va">self</span><span class="op">$</span><span class="va">layer</span> <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="va">in_features</span>, <span class="va">out_features</span>, bias <span class="op">=</span> <span class="va">bias</span><span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="op">}</span>,</span></span>
<span class="r-in"><span>        forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">self</span><span class="op">$</span><span class="fu">layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="va">custom_arch</span> <span class="op">=</span> <span class="fu"><a href="nn_arch.html">nn_arch</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>        nn_name <span class="op">=</span> <span class="st">"custom_linear_mlp"</span>,</span></span>
<span class="r-in"><span>        nn_layer <span class="op">=</span> <span class="op">~</span> <span class="va">custom_linear</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span>,</span></span>
<span class="r-in"><span>        data <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">16</span>, <span class="fl">8</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        architecture <span class="op">=</span> <span class="va">custom_arch</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">50</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>    <span class="co"># With early stopping</span></span></span>
<span class="r-in"><span>    <span class="va">model</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">.</span>,</span></span>
<span class="r-in"><span>        data <span class="op">=</span> <span class="va">iris</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">200</span>,</span></span>
<span class="r-in"><span>        validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span></span>
<span class="r-in"><span>        early_stopping <span class="op">=</span> <span class="fu"><a href="early_stop.html">early_stop</a></span><span class="op">(</span>patience <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_is_installed.html" class="external-link">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>    <span class="co"># torch dataset method — labels come from the dataset itself</span></span></span>
<span class="r-in"><span>    <span class="va">iris_cls_dataset</span> <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/dataset.html" class="external-link">dataset</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>        name <span class="op">=</span> <span class="st">"iris_cls_dataset"</span>,</span></span>
<span class="r-in"><span>        </span></span>
<span class="r-in"><span>        initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span> <span class="op">=</span> <span class="va">iris</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>            <span class="va">self</span><span class="op">$</span><span class="va">x</span> <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>                <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                dtype <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_dtype.html" class="external-link">torch_float32</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span>            <span class="op">)</span></span></span>
<span class="r-in"><span>            <span class="co"># Species is a factor; convert to integer (1-indexed -&gt; keep as-is for cross_entropy)</span></span></span>
<span class="r-in"><span>            <span class="va">self</span><span class="op">$</span><span class="va">y</span> <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>                <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                dtype <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_dtype.html" class="external-link">torch_long</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span>            <span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="op">}</span>,</span></span>
<span class="r-in"><span>        </span></span>
<span class="r-in"><span>        .getitem <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>            <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="va">i</span>, <span class="op">]</span>, <span class="va">self</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="op">}</span>,</span></span>
<span class="r-in"><span>        </span></span>
<span class="r-in"><span>        .length <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>            <span class="va">self</span><span class="op">$</span><span class="va">x</span><span class="op">$</span><span class="fu">size</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="op">}</span></span></span>
<span class="r-in"><span>    <span class="op">)</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="va">model_nn_ds</span> <span class="op">=</span> <span class="fu">train_nn</span><span class="op">(</span></span></span>
<span class="r-in"><span>        x <span class="op">=</span> <span class="va">iris_cls_dataset</span>,</span></span>
<span class="r-in"><span>        hidden_neurons <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">10</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>        activations <span class="op">=</span> <span class="st">"relu"</span>,</span></span>
<span class="r-in"><span>        epochs <span class="op">=</span> <span class="fl">80</span>,</span></span>
<span class="r-in"><span>        batch_size <span class="op">=</span> <span class="fl">16</span>,</span></span>
<span class="r-in"><span>        learn_rate <span class="op">=</span> <span class="fl">0.01</span>,</span></span>
<span class="r-in"><span>        n_classes <span class="op">=</span> <span class="fl">3</span>, <span class="co"># Iris dataset has only 3 species</span></span></span>
<span class="r-in"><span>        validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span></span>
<span class="r-in"><span>        verbose <span class="op">=</span> <span class="cn">TRUE</span></span></span>
<span class="r-in"><span>    <span class="op">)</span></span></span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="va">pred_nn</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_nn_ds</span>, <span class="va">iris_cls_dataset</span><span class="op">)</span></span></span>
<span class="r-in"><span>    <span class="va">class_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Setosa"</span>, <span class="st">"Versicolor"</span>, <span class="st">"Virginica"</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_nn_ds</span>, <span class="va">iris_cls_dataset</span><span class="op">)</span><span class="op">]</span></span></span>
<span class="r-in"><span>    </span></span>
<span class="r-in"><span>    <span class="co"># Confusion Matrix</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span>actual <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Species</span>, pred <span class="op">=</span> <span class="va">class_preds</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> → Auto-detected classification task. Using cross_entropy loss.</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Using device: cpu</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 8/80 - Loss: 0.1822 - Val Loss: 0.2568</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 16/80 - Loss: 0.0679 - Val Loss: 0.2465</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 24/80 - Loss: 0.1994 - Val Loss: 0.4451</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 32/80 - Loss: 0.0575 - Val Loss: 0.1358</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 40/80 - Loss: 0.0573 - Val Loss: 0.1236</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 48/80 - Loss: 0.0794 - Val Loss: 0.1265</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 56/80 - Loss: 0.0528 - Val Loss: 0.1135</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 64/80 - Loss: 0.0600 - Val Loss: 0.1220</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 72/80 - Loss: 0.0530 - Val Loss: 0.1114</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Epoch 80/80 - Loss: 0.0617 - Val Loss: 0.1128</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>             pred</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> actual       Setosa Versicolor Virginica</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   setosa         50          0         0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   versicolor      0         48         2</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   virginica       0          2        48</span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Joshua Marie, Antoine Soetewey.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a>. Visit my <a href="https://joshuamarie.com" class="external-link">blog</a> for more content.</p>
</div>

    </footer></div>





  </body></html>

